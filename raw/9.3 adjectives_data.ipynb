{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled words saved to sampled_words.json\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "random.seed(42)\n",
    "\n",
    "# Read words from the file\n",
    "with open('top-1000-nouns.txt', 'r') as f:\n",
    "    words = f.read().splitlines()\n",
    "\n",
    "# Check if there are at least 150 words in the file\n",
    "if len(words) < 150:\n",
    "    raise ValueError(\"The file contains fewer than 150 words.\")\n",
    "\n",
    "# Randomly sample 150 words\n",
    "sampled_words = random.sample(words, 100)\n",
    "\n",
    "# Structure the data for JSON\n",
    "data = {\"English\": sampled_words}\n",
    "\n",
    "# Save the sampled words to a JSON file\n",
    "with open('sampled_words.json', 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n",
    "\n",
    "print('Sampled words saved to sampled_words.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sampled_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from googletrans import Translator\n",
    "t = Translator()\n",
    "\n",
    "def translate_words(words,dest_lang):\n",
    "    translated_words = []\n",
    "    for word in words:\n",
    "        translated_word = t.translate(word, src='en', dest=dest_lang).text\n",
    "        translated_words.append(translated_word)\n",
    "        \n",
    "    return(translated_words)\n",
    "\n",
    "\n",
    "def sample_words(file_name,rand_seed):\n",
    "    random.seed(rand_seed)\n",
    "    with open(file_name, 'r') as f:\n",
    "        words = f.read().splitlines()\n",
    "    sampled_words = random.sample(words, 100)\n",
    "    \n",
    "    return(sampled_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_adj = sample_words('english_adjectives.txt',42)\n",
    "german_adj = translate_words(sample_words('english_adjectives.txt',101),'de')\n",
    "dutch_adj = translate_words(sample_words('english_adjectives.txt',101),'nl')\n",
    "swedish_adj = translate_words(sample_words('english_adjectives.txt',101),'sv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_adj = translate_words(sample_words('french_adjectives.txt',42),'es')\n",
    "french_adj = sample_words('french_adjectives.txt',101)\n",
    "portuguese_adj = translate_words(sample_words('french_adjectives.txt',333),'pt')\n",
    "italian_adj = translate_words(sample_words('french_adjectives.txt',911),'it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attraente',\n",
       " 'contenuto',\n",
       " 'positivo',\n",
       " 'épuisé',\n",
       " 'pareil',\n",
       " 'rossetto',\n",
       " 'époustouflant',\n",
       " 'nuageux',\n",
       " 'umidificare',\n",
       " 'rapido',\n",
       " 'épais',\n",
       " 'pallido',\n",
       " 'vieux',\n",
       " 'fatica',\n",
       " 'proprio',\n",
       " 'impoli',\n",
       " 'pauvre',\n",
       " 'caro',\n",
       " 'negativo',\n",
       " 'seul',\n",
       " 'bouclé',\n",
       " 'Chiara',\n",
       " 'Viola',\n",
       " 'compliqué',\n",
       " 'grande',\n",
       " 'stupido',\n",
       " 'pret',\n",
       " 'blasè',\n",
       " 'rosa',\n",
       " 'precedente',\n",
       " 'penché',\n",
       " 'leggero',\n",
       " 'dolce',\n",
       " 'brillante',\n",
       " 'mignon',\n",
       " 'buongustaio',\n",
       " 'affascinante',\n",
       " 'navre',\n",
       " 'pinna',\n",
       " 'pluvieux',\n",
       " 'lavoratore',\n",
       " 'bianco',\n",
       " 'comodo',\n",
       " 'lombo',\n",
       " 'forte',\n",
       " 'ensoleillé',\n",
       " 'divertente',\n",
       " 'mauvais',\n",
       " 'inquieto',\n",
       " 'freddo',\n",
       " 'fantastico',\n",
       " 'sfacciato',\n",
       " 'tranquillo',\n",
       " 'lordo',\n",
       " 'coraggioso',\n",
       " 'impaziente',\n",
       " 'ravi',\n",
       " 'rigoroso',\n",
       " 'voluminoso',\n",
       " 'formidabile',\n",
       " 'passionale',\n",
       " 'fou',\n",
       " 'rieur',\n",
       " 'triste',\n",
       " 'Porsche',\n",
       " 'bizzarro',\n",
       " 'robusto',\n",
       " 'vert',\n",
       " 'leggero',\n",
       " 'calma',\n",
       " 'arancia',\n",
       " 'caldo',\n",
       " 'paziente',\n",
       " 'pittoresco',\n",
       " 'bronzo',\n",
       " 'sez',\n",
       " 'emotivo',\n",
       " 'drôle',\n",
       " 'Tribunale',\n",
       " 'plein',\n",
       " 'gentile',\n",
       " 'giovane',\n",
       " 'joli',\n",
       " 'dernier',\n",
       " 'curieux',\n",
       " 'doué',\n",
       " 'simpatico',\n",
       " 'difficile',\n",
       " 'rovinato',\n",
       " 'fabile',\n",
       " 'venimeux',\n",
       " 'utile',\n",
       " 'migliore',\n",
       " 'gigantesco',\n",
       " 'ricco',\n",
       " 'prestato',\n",
       " 'poli',\n",
       " 'noir',\n",
       " 'distensione',\n",
       " 'Signore']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "italian_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure the data for JSON\n",
    "data = {\"English\": english_adj,\n",
    "        \"German\": german_adj,\n",
    "        \"Dutch\": dutch_adj,\n",
    "        \"Swedish\": swedish_adj\n",
    "        }\n",
    "\n",
    "# Save the sampled words to a JSON file\n",
    "with open('Germanic_full_adj.json', 'w', encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure the data for JSON\n",
    "data = {\"Spanish\": spanish_adj,\n",
    "        \"French\": french_adj,\n",
    "        \"Portuguese\": portuguese_adj,\n",
    "        \"Italian\": italian_adj\n",
    "        }\n",
    "\n",
    "# Save the sampled words to a JSON file\n",
    "with open('Romance_full_adj.json', 'w', encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(file_path, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Extract data from the second column\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Adjust the column index or name according to your file structure\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m second_column_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# '1' assumes columns start at 0\u001b[39;00m\n\u001b[0;32m     13\u001b[0m second_column_text \u001b[38;5;241m=\u001b[39m second_column_data\u001b[38;5;241m.\u001b[39mto_string(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Save the data to a text file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marin\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1147\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\marin\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1652\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m-> 1652\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1654\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[1;32mc:\\Users\\marin\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:940\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(k, i)\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    942\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation based indexing can only have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] types\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    945\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marin\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1554\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(key):\n\u001b[1;32m-> 1554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m   1556\u001b[0m     \u001b[38;5;66;03m# a tuple should already have been caught by this point\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;66;03m# so don't treat a tuple as a valid indexer\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indexers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\marin\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1645\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'french_adjectives.xlsx'  # Replace 'your_file.xlsx' with the path to your file\n",
    "data = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "# Extract data from the second column\n",
    "# Adjust the column index or name according to your file structure\n",
    "second_column_data = data.iloc[:, 1]  # '1' assumes columns start at 0\n",
    "\n",
    "second_column_text = second_column_data.to_string(index=False, header=False)\n",
    "\n",
    "# Save the data to a text file\n",
    "\n",
    "with open('french_adjectives.txt', 'w') as file:\n",
    "    file.write(second_column_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "excel_file = 'french_adjectives.xlsx'  # Replace with your Excel file path\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Open a text file to write the output\n",
    "with open('french_adjectives.txt', 'w') as file:\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Convert each row to a string and write it to the text file\n",
    "        file.write(', '.join(row.astype(str)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Path to your text file\n",
    "file_path = 'output.txt'\n",
    "\n",
    "# Read the first 150 lines from the text file\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = [next(file).strip() for _ in range(150)]\n",
    "\n",
    "# Create a dictionary with these lines under the category \"Spanish\"\n",
    "data = {'German': german_words}\n",
    "\n",
    "# Path to the JSON file where you want to save the data\n",
    "json_file_path = 'Romance.json'\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read the file\n",
    "with open('spanish-2000.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Process the lines\n",
    "filtered_lines = []\n",
    "for line in lines:\n",
    "    # Remove the text after '/' and the '/' symbol itself\n",
    "    line = re.sub(r'/.*', '', line).strip()\n",
    "    # Keep the line only if it has one or no words\n",
    "    if len(line.split()) <= 1:\n",
    "        filtered_lines.append(line + '\\n')\n",
    "\n",
    "# Write the filtered lines back to a new file\n",
    "with open('filtered_file.txt', 'w') as file:\n",
    "    file.writelines(filtered_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with these lines under the category \"Spanish\"\n",
    "data = {'Spanish': spanish_adj}\n",
    "\n",
    "# Path to the JSON file where you want to save the data\n",
    "json_file_path = 'Romance_adj.json'\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spanish_verbs.txt', 'r') as file, open('spanish_verbs_clean.txt', 'w') as output:\n",
    "    # Read through each line in the file\n",
    "    for line in file:\n",
    "        # Split the line into words and check if it contains more than one word\n",
    "        if len(line.split()) <= 1:\n",
    "            # If it contains 0 or 1 word, write it to the new file\n",
    "            output.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
