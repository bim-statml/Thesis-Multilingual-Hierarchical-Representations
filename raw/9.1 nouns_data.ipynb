{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/plants.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the JSON file\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/plants.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Loop through all categories and count entries\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marin\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/plants.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"data/plants.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Loop through all categories and count entries\n",
    "category_counts = {}\n",
    "\n",
    "for category, entries in data.items():\n",
    "    category_counts[category] = len(entries)\n",
    "\n",
    "# Print the count of entries for each category\n",
    "for category, count in category_counts.items():\n",
    "    print(f'The number of entries in the \"{category}\" category is: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'top-1000-nouns.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Read words from the file\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop-1000-nouns.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      7\u001b[0m     words \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Check if there are at least 150 words in the file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marin\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'top-1000-nouns.txt'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "random.seed(42)\n",
    "\n",
    "# Read words from the file\n",
    "with open('top-1000-nouns.txt', 'r') as f:\n",
    "    words = f.read().splitlines()\n",
    "\n",
    "# Check if there are at least 150 words in the file\n",
    "if len(words) < 150:\n",
    "    raise ValueError(\"The file contains fewer than 150 words.\")\n",
    "\n",
    "# Randomly sample 150 words\n",
    "sampled_words = random.sample(words, 100)\n",
    "\n",
    "# Structure the data for JSON\n",
    "data = {\"English\": sampled_words}\n",
    "\n",
    "# Save the sampled words to a JSON file\n",
    "with open('sampled_words.json', 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n",
    "\n",
    "print('Sampled words saved to sampled_words.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sampled_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "t = Translator()\n",
    "\n",
    "def translate_words(words,dest_lang):\n",
    "    translated_words = []\n",
    "    for word in words:\n",
    "        translated_word = t.translate(word, src='en', dest=dest_lang).text\n",
    "        translated_words.append(translated_word)\n",
    "        \n",
    "    return(translated_words)\n",
    "\n",
    "\n",
    "def sample_words(file_name,rand_seed):\n",
    "    random.seed(rand_seed)\n",
    "    with open(file_name, 'r') as f:\n",
    "        words = f.read().splitlines()\n",
    "    sampled_words = random.sample(words, 100)\n",
    "    \n",
    "    return(sampled_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#english_words = sample_words(42)\n",
    "german_words = translate_words(sample_words('top-1000-nouns.txt',101),'de')\n",
    "#dutch_words = translate_words(sample_words(333),'nl')\n",
    "#swedish_words = translate_words(sample_words(911),'nl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_words = sample_words('filtered_spanish_2000.txt',42)\n",
    "french_words = translate_words(sample_words('filtered_spanish_2000.txt',101),'fr')\n",
    "portuguese_words = translate_words(sample_words('filtered_spanish_2000.txt',333),'pt')\n",
    "italian_words = translate_words(sample_words('filtered_spanish_2000.txt',911),'it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['derrota',\n",
       " 'par',\n",
       " 'mentiroso/mentirosa',\n",
       " 'pollo',\n",
       " 'ganador/ganadora',\n",
       " 'maestro',\n",
       " 'crédito',\n",
       " 'caridade',\n",
       " 'pis (gíria)',\n",
       " 'página',\n",
       " 'restos',\n",
       " 'local',\n",
       " 'animal',\n",
       " 'semilla',\n",
       " 'Nieto',\n",
       " 'discurso',\n",
       " 'impressão',\n",
       " 'couro',\n",
       " 'beleza',\n",
       " 'sobre',\n",
       " 'borda',\n",
       " 'tiron',\n",
       " 'viagem',\n",
       " 'jogo',\n",
       " 'combinação',\n",
       " 'companheiro',\n",
       " 'bar',\n",
       " 'regular',\n",
       " 'Sol',\n",
       " 'círculo',\n",
       " 'amarrar',\n",
       " 'baneira',\n",
       " 'granjero',\n",
       " 'marea',\n",
       " 'cassino',\n",
       " 'esquina',\n",
       " 'firme',\n",
       " 'espia',\n",
       " 'testículo',\n",
       " 'qualidade',\n",
       " 'consenso',\n",
       " 'estudante',\n",
       " 'mudança',\n",
       " 'programa',\n",
       " 'cárcel',\n",
       " 'oreja',\n",
       " 'causa',\n",
       " 'sartén',\n",
       " 'anúncio',\n",
       " 'em geral',\n",
       " 'meio',\n",
       " 'pedezo',\n",
       " 'inversão',\n",
       " 'sangue',\n",
       " 'gerente',\n",
       " 'perfil',\n",
       " 'tecnologia',\n",
       " 'setor',\n",
       " 'Hedor',\n",
       " 'tarde',\n",
       " 'humor',\n",
       " 'homem',\n",
       " 'tenho um',\n",
       " 'maestro/condutor',\n",
       " 'interruptor',\n",
       " 'oceano',\n",
       " 'representação',\n",
       " 'escalar',\n",
       " 'desagüe',\n",
       " 'século',\n",
       " 'apetite',\n",
       " 'jugo (América Latina), zumo (Espanha)',\n",
       " 'luz',\n",
       " 'dados',\n",
       " 'competência',\n",
       " 'marca',\n",
       " 'equipo (engrenagem), marcha (engrenagem em um veículo)',\n",
       " 'honestidade',\n",
       " 'total',\n",
       " 'comida',\n",
       " 'ventana',\n",
       " 'acordo',\n",
       " 'periodista',\n",
       " 'gente',\n",
       " 'jamón',\n",
       " 'oferta',\n",
       " 'bateria',\n",
       " 'veredicto',\n",
       " 'entrevista',\n",
       " 'móveis',\n",
       " 'Pato',\n",
       " 'pulimento',\n",
       " 'crise',\n",
       " 'buceo',\n",
       " 'rua',\n",
       " 'cena',\n",
       " 'abuso',\n",
       " 'humanidade',\n",
       " 'barbatana',\n",
       " 'vaqueiro']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure the data for JSON\n",
    "data = {\"English\": english_words,\n",
    "        \"German\": german_words,\n",
    "        \"Dutch\": dutch_words,\n",
    "        \"Swedish\": swedish_words\n",
    "        }\n",
    "\n",
    "# Save the sampled words to a JSON file\n",
    "with open('Germanic_full.json', 'w', encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure the data for JSON\n",
    "data = {\"Spanish\": spanish_words,\n",
    "        \"French\": french_words,\n",
    "        \"Portuguese\": portuguese_words,\n",
    "        \"Italian\": italian_words\n",
    "        }\n",
    "\n",
    "# Save the sampled words to a JSON file\n",
    "with open('Romance_full.json', 'w', encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'spanish_nouns.xlsx'  # Replace 'your_file.xlsx' with the path to your file\n",
    "data = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "# Extract data from the second column\n",
    "# Adjust the column index or name according to your file structure\n",
    "second_column_data = data.iloc[:, 1]  # '1' assumes columns start at 0\n",
    "\n",
    "second_column_text = second_column_data.to_string(index=False, header=False)\n",
    "\n",
    "# Save the data to a text file\n",
    "\n",
    "with open('output.txt', 'w') as file:\n",
    "    file.write(second_column_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "excel_file = 'english_verbs.xlsx'  # Replace with your Excel file path\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Open a text file to write the output\n",
    "with open('english_verbs.txt', 'w') as file:\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Convert each row to a string and write it to the text file\n",
    "        file.write(', '.join(row.astype(str)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Path to your text file\n",
    "file_path = 'output.txt'\n",
    "\n",
    "# Read the first 150 lines from the text file\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = [next(file).strip() for _ in range(150)]\n",
    "\n",
    "# Create a dictionary with these lines under the category \"Spanish\"\n",
    "data = {'German': german_words}\n",
    "\n",
    "# Path to the JSON file where you want to save the data\n",
    "json_file_path = 'Romance.json'\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read the file\n",
    "with open('spanish-2000.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Process the lines\n",
    "filtered_lines = []\n",
    "for line in lines:\n",
    "    # Remove the text after '/' and the '/' symbol itself\n",
    "    line = re.sub(r'/.*', '', line).strip()\n",
    "    # Keep the line only if it has one or no words\n",
    "    if len(line.split()) <= 1:\n",
    "        filtered_lines.append(line + '\\n')\n",
    "\n",
    "# Write the filtered lines back to a new file\n",
    "with open('filtered_file.txt', 'w') as file:\n",
    "    file.writelines(filtered_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with these lines under the category \"Spanish\"\n",
    "data = {'German': german_words}\n",
    "\n",
    "# Path to the JSON file where you want to save the data\n",
    "json_file_path = 'Germanic.json'\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
